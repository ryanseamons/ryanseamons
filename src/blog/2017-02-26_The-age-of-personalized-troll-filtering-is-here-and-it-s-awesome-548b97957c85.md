# The age of personalized troll filtering is here and it’s awesome

Personalization is the future: the future of education (which is one of the reasons why I work at Degreed and homeschool my kids), the…

![See how you can set the level of toxicity and change what comments appear on your feed](https://cdn-images-1.medium.com/max/800/1*T_e7JpptIUHre-XXY5jbhA.png)
See how you can set the level of toxicity and change what comments appear on your feed

Personalization is the future: the future of education (which is one of the reasons why I work at Degreed and homeschool my kids), the future of manufacturing (3d printers), and now, the future of conversation and trolls.

Recently, both [Google](https://www.wired.com/2017/02/googles-troll-fighting-ai-now-belongs-world/) and [Facebook](http://www.recode.net/2017/2/16/14640460/mark-zuckerberg-facebook-manifesto-letter) made announcements related to the future of filtering on the web and I like it.

### Google’s Perspective

[Perspective](http://www.perspectiveapi.com/) is a project created by Jigsaw and Google’s Counter Abuse Technology team. Their [demonstration site](http://www.perspectiveapi.com/) lets you see how statements rate on a toxicity scale.

![](https://cdn-images-1.medium.com/max/600/1*rI3VliQIZL-YokYaXTyEYw.png)
![](https://cdn-images-1.medium.com/max/400/1*9vjPOTviY9A_MOy7gOWihQ.png)
![You can see how different statements are rated for potential toxicity.](https://cdn-images-1.medium.com/max/400/1*nJlKW3l6BNqa73IDW2k_Xg.png)
You can see how different statements are rated for potential toxicity.

Perspective will be most powerful when used as a way to help existing curation methods.

> “The New York Times is planning to use \[Perspective\] as a first pass of all its comments, automatically flagging abusive ones for its team of human moderators.”

This improves existing censoring models. Current options include blacklisting certain words/users or shutting off comments completely. But Perspective allows sites to better prioritize which comments to review or even allow individuals to set their own preference for what they see.

### Mark Zuckerberg and Facebook’s Global Ambitions

In the [Mark Manifesto](http://www.recode.net/2017/2/16/14640460/mark-zuckerberg-facebook-manifesto-letter) (about the future ambitions of Facebook) Zuckerberg shares some current and future plans for filtering on Facebook.

Thoughts on filtering in coordination with human decision:

> Looking ahead, one of our greatest opportunities to keep people safe is building artificial intelligence to understand more quickly and accurately what is happening across our community.

…

> Artificial intelligence can help provide a better approach. We are researching systems that can look at photos and videos to flag content our team should review. This is still very early in development, but we have started to have it look at some content, and it already generates about one-third of all reports to the team that reviews content for our community.

![Facebook’s future plans include far more sophisticated models of personal filtering](https://cdn-images-1.medium.com/max/800/1*bpMLagPf-XC4dilkEChzOw.png)
Facebook’s future plans include far more sophisticated models of personal filtering

Additionally, the realization that sensationalism in media and commenting makes it harder to have real discussion:

> Polarization exists in all areas of discourse, not just social media. It occurs in all groups and communities, including companies, classrooms and juries, and it’s usually unrelated to politics. In the tech community, for example, discussion around AI has been oversimplified to existential fear-mongering. The harm is that sensationalism moves people away from balanced nuanced opinions towards polarized extremes.

> If this continues and we lose common understanding, then even if we eliminated all misinformation, people would just emphasize different sets of facts to fit their polarized opinions. That’s why I’m so worried about sensationalism in media.

While Facebook has its issues, the idea of a platform that creates and supports meaningful communities is noble. Again, this comes back to the issue of who sets the filtering. Thoughts about the community influencing their own filters is a great improvement on past filtering attempts.

### Vidangel is already enabling personalized filtering

![](https://cdn-images-1.medium.com/max/800/1*I86-8_6H_fHt8WTfjzJJ5g.png)

One other example of a company on the forefront of filtering is [Vidangel](https://www.vidangel.com/). Vidangel is already providing individuals with personalized filtering for movies (or trying to in the midst of a lawsuit from studios who have continually shown animosity for personalized filtering). Vidangel allows studios to make movies how they want and individuals to consumer how they want. It’s a brilliant way to allow for **freedom to create and to consume.** I’m very much rooting for them in their court case.

![](https://cdn-images-1.medium.com/max/800/1*n3mqr9AYlMUUMIwHa4nvSw.png)

VidAngel has done it better than anyone ever has, and make some convincing arguments about why they should be allowed to do what they do. For example, they are enabling the Family Movie Act of 2005 and have pursued many avenues to partner with studios to enable this.

Government and companies haven’t done a great job with enabling or setting filtering. **Individuals and communities know how to best filter and technology is the tool allowing them to do it.**

### The future of filtering is bright

These types of personalization that Google, Facebook, and Vidangel invision will help more people stay in the conversation. **More people listening and participating in constructive conversation benefits everyone.** The worst thing we could do is give up hope and disengage from the discussion; that’s the biggest issue with trolling. Similar to how terrorism causes people to change their public behaviors because of fear, trolling causes people to not join conversation out of fear. However, when we converse, we learn.

**We all have different levels of comfort with language and should be able to control how inappropriate or intense it should be.** To think about having personal control over what you read and see is amazing. There is lots to still figure out, but I like the direction we’re taking.

By [Ryan Seamons](https://medium.com/@ryanseamons) on [February 26, 2017](https://medium.com/p/548b97957c85).

[Canonical link](https://medium.com/@ryanseamons/the-age-of-personalized-troll-filtering-is-here-and-its-awesome-548b97957c85)

Exported from [Medium](https://medium.com) on January 28, 2020.